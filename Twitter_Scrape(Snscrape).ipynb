{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Twitter Scraping"
      ],
      "metadata": {
        "id": "qKuOvHvk4hV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Snscrape is a scraper for social networking services (SNS). It scrapes things like user profiles, hashtags, or searches and returns the discovered items, e.g. the relevant posts.\n",
        "- Twitter: users, user profiles, hashtags, searches (live tweets, top tweets, and users), tweets (single or surrounding thread), list posts, communities, and trends\n",
        "\n",
        "Snscrape offers users the capability to extract various elements such as user profiles and hashtags. This robust tool enables users to retrieve different types of search results, including live tweets, top tweets, and user information"
      ],
      "metadata": {
        "id": "i2134x2x38jE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfuOtqdYbHnL",
        "outputId": "d219576c-9908-44e6-f9ea-9a25aff04e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snscrape\n",
            "  Downloading snscrape-0.6.2.20230320-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from snscrape) (3.11.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from snscrape) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->snscrape) (2.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.26.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.6.2.20230320\n"
          ]
        }
      ],
      "source": [
        "pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xBbSTkRjaoM"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VidNQhzWqMnC",
        "outputId": "83bff444-9874-4405-9105-ecff7933ec3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-63b55914cc12>:10: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
            "  tweets.append([tweet.date, tweet.id, tweet.url, tweet.user.username, tweet.sourceLabel, tweet.user.location, tweet.content, tweet.likeCount, tweet.retweetCount])\n"
          ]
        }
      ],
      "source": [
        "query = '(COVID-19 Booster) since:2021-05-01 until:2022-12-31'\n",
        "tweets = []\n",
        "\n",
        "# limit = 1000000\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "  # if limit:\n",
        "  #   break\n",
        "  # else:\n",
        "  tweets.append([tweet.date, tweet.id, tweet.url, tweet.user.username, tweet.sourceLabel, tweet.user.location, tweet.content, tweet.likeCount, tweet.retweetCount])\n",
        "\n",
        "df = pd.DataFrame(tweets, columns=['Date', 'Id', 'URL', 'Username', 'Source', 'Location', 'Tweet', 'LikeCount', 'RetweetCount'])\n",
        "\n",
        "df.to_csv('twitter_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZkluZTa3qaq"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"TwitterTrans_dataset.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}